# About the Project
A web crawler is designed to "crawl" through different websites and index them for use in search engines like Google and Bing. This coding project is designed to be a smaller implementation of the web crawler, by crawling
through HTML files recursively or iteratively depending on the crawler used. It does this by keeping track of the pages that it skipped or already visited. 
